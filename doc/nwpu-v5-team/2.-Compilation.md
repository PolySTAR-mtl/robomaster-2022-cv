# Environment

## Host 

| Environment | Version |
| --- | --- |
| OS | Ubuntu 18.04 |
| Build System | Catkin Build System |
| CUDA (optional) | 10.2 |
| TensorRT (optional) | 7.0.0 |
| libtorch | cxx11版本 |
| pytorch | 1.5 |
| onnx | 1.1 |
| netron (optional) | / |

## Device

| Environment | Version |
| --- | --- |
| OS | Ubuntu18.04 |
| jetpack package | JetPack  4.4 |
| CUDA  | 10.2 |
| TensorRT | 7.0.0 |
| OpenCV | 4.2 |

# Compilation

First, install the corresponding dependencies. Ubuntu 18.04 is recommended. 
```shell
sudo apt-get install -y ros-melodic-opencv3             \
                        ros-melodic-cv-bridge           \
                        ros-melodic-image-transport     \
                        ros-melodic-stage-ros           \
                        ros-melodic-map-server          \
                        ros-melodic-laser-geometry      \
                        ros-melodic-interactive-markers \
                        ros-melodic-tf                  \
                        ros-melodic-pcl-*               \
                        ros-melodic-libg2o              \
                        ros-melodic-rplidar-ros         \
                        ros-melodic-rviz                \
                        protobuf-compiler               \
                        libprotobuf-dev                 \
                        libsuitesparse-dev              \
                        libgoogle-glog-dev              \
                        
```
**Libtorch** is the c++ version package provided by pytorch, based on 
**caffe2 aten** and **c10**. We can install the compiled version directly. 
It should be noted that there are two versions of **libtorch**. One uses 
**C11** and the other uses the previous standard of C11. 
Be careful that this version may possibly not compile with ROS. 
However high frame rate is not required here, so the computation can be purely 
done with CPU.

```shell
wget https://download.pytorch.org/libtorch/cpu/libtorch-cxx11-abi-shared-with-deps-1.6.0%2Bcpu.zip
unzip libtorch.zip
sudo mv libtorch /usr/local/
```

## CUDA 10.2 Installation
[NVIDIA CUDA10.2](https://developer.nvidia.com/cuda-10.2-download-archive?target_os=Linux&target_arch=x86_64&target_distro=Ubuntu&target_version=1804&target_type=deblocal)

```shell
wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/cuda-ubuntu1804.pin
sudo mv cuda-ubuntu1804.pin /etc/apt/preferences.d/cuda-repository-pin-600
wget http://developer.download.nvidia.com/compute/cuda/10.2/Prod/local_installers/cuda-repo-ubuntu1804-10-2-local-10.2.89-440.33.01_1.0-1_amd64.deb
sudo dpkg -i cuda-repo-ubuntu1804-10-2-local-10.2.89-440.33.01_1.0-1_amd64.deb
sudo apt-key add /var/cuda-repo-10-2-local-10.2.89-440.33.01/7fa2af80.pub
sudo apt-get update
sudo apt-get -y install cuda
```

## TensorRt 7.0.0 Installation
[NVIDIA TensorRT 7.0.0](https://developer.nvidia.com/nvidia-tensorrt-7x-download) 

Download the deb package directly from the official website, unzip the file, 
and complete the installation. 

# Guide

## Using SSD-detection

### Training

- Set your dataset (voc) path which contains images, annotation directory 
in ./utils/setting_dict.py

```json
"test" : {
            "data_set" : ["/DJI/DJItest"],
            "batch_size" : 2,
            "transform" :
                {
                    "PIXEL_MEAN" : [123, 117, 104],
                    "IMAGE_SIZE" : 512,
                }
        },
    
   "train": {
            "data_set" :  ["/DJI/DJItrain/"],
            "batch_size" : 8,
            "transform" :
                {
                    "PIXEL_MEAN" : [123, 117, 104],
                    "IMAGE_SIZE" : 512,
                },
```

- run the train.py  

```shell
python3  train.py 
```

- (optional) specify the output path
your can view the loss using tensorboard if you wish, the loss will be stored in output directory  

```shell
python3 train.py  --out_dir {YOUR_PATH}
```

### Testing

```shell
python3 test.py
```

### Fine-tuning

```shell
python3 train.py --fine_tune 1  --pretrained_model "{PRETRAINED_MODEL_PATH}"
```

## Using RTS-deploy

```shell
rosrun ICRA-vision ICRA_vision
```
