# 哨岗相机

## 定位原理

基本原理是 sfm(Structure From Motion)， 通过一系列运动图像，求得相机位姿，然后加入带有尺度信息的一组图片（拍摄的位置已知），然后进行三维重建，最后得到放置哨岗相机处成像平面相对地图原点位姿，然后检测到的机器人像素坐标通过内参矩阵与地面平面方程联立方程组，解得地面平面坐标。

## 相机位姿求解
整个模块的任务是获取固定在高空2m左右的哨岗相机相对于地图中心坐标点所在坐标系的变换矩阵。我们基于增量式sfm算法，对每张图片检测特征点，再对每对图片中的特征点进行匹配，只保留满足几何约束的匹配，最后执行一个迭代式的、鲁棒的SfM方法来估计摄像机的内参和外参，由于内参已经事先进行标定，因此只需要获取结果中的外参，即相机到世界的坐标变换矩阵。

<div align="center">
​ ​<img src="https://cdn.nlark.com/yuque/0/2020/png/2394508/1598452134477-e9fbb63d-5476-4116-b221-5d3c4307b92e.png" width="50%" height="50%">
  <br> 图 5.1 三维重建效果图 </br>
</div>


<div align="center">
​ ​​ <img src="https://cdn.nlark.com/yuque/0/2020/png/2394508/1598453274945-e86a281a-db73-46be-85f7-e5cc146817f7.png" width="50%" height="50%">
  <br> 图 5.2 哨岗相机视角以及特征点 </br>
</div>

<div align="center">
​ ​​ <img src="https://cdn.nlark.com/yuque/0/2020/png/2394508/1598453564886-b5cc3a54-80ce-41be-be4a-37b7354e95b0.png" width="50%" height="50%">
  <br> 图 5.3 哨岗相机与其他相机位置共视 </br>
</div>

利用colmap，可以完成三维重建，利用高精度的三维重建效果获得相机位置以及姿态，将相机放置在已知位置，可以获得尺度信息，消除建图的尺度不确定性，并且可以获得建图坐标系与场地世界坐标转换关系。

<div align="center">
​ ​​ <img src="https://cdn.nlark.com/yuque/0/2020/png/2394508/1598459411670-faa23958-e445-4dd2-a3e6-001de5b3ac4f.png" width="50%" height="50%">
  <br> 图 5.4 特殊标定位置 </br>
</div>
  

## 机器人坐标求解

由之前的检测算法我们可以得到在相机图片里，框出目标机器人位置的方框，以及机器人所在图片中位置的二维点坐标，我们将此坐标定义为像素坐标系下的坐标，并且用![](https://cdn.nlark.com/yuque/__latex/58f1e17cae79f8b2b1dfcb232ca5d81f.svg)表示。

我们将展示基于程序运行过程中具体某一帧的实例来形象地解释相机检测过程中对机器人坐标求解问题。如下图所示，我们从目标检测模块或者目标跟踪获得了目标机器人在二维图像中的坐标点，我们取图中红色方框圈出的红色二号机器人为例。设该方框中心的图像坐标为![](https://cdn.nlark.com/yuque/__latex/9093cc72d2d40694b9361424cb0a6803.svg),已知该相机的内参矩阵为

![](https://cdn.nlark.com/yuque/__latex/3ce701d66be55596ad8a6f63a2e2f071.svg)



那么我们根据像素坐标系到相机坐标系的转换关系可以求得机器人在相机坐标系下的坐标点,记为![](https://cdn.nlark.com/yuque/__latex/4c9bcdffbbf10c267a092c166f30fe77.svg#card=math&code=P_c%28x_c%2Cy_c%2Cz_c%29&height=18&width=82),其中由于目标位置到相机光心的深度未知，![](https://cdn.nlark.com/yuque/__latex/8bdb1ea46685195d8f6cb68b7275c786.svg#card=math&code=z_c&height=12&width=12)是未知的，但是我们可以将该坐标点归一化到![](https://cdn.nlark.com/yuque/__latex/031b3f162046ccf256b9c57863965b72.svg#card=math&code=z_c%20%3D1&height=16&width=40)的平面上，则此时相机的坐标点可以表示为![](https://cdn.nlark.com/yuque/__latex/ea03d7867b7eaf00be30b327acc64698.svg#card=math&code=P_c%28x_c%5E%7B%5Cprime%7D%2Cy_c%5E%7B%5Cprime%7D%2C1%29&height=18&width=76),其中包含以下关系：

![](https://cdn.nlark.com/yuque/__latex/f90856e1b50853ea2eecfa4048abb300.svg#card=math&code=x_c%5E%7B%5Cprime%7D%20%3D%20x_c%20%2Fz_c%20%5C%5C%0Ay_c%5E%7B%5Cprime%7D%20%3D%20y_c%20%2F%20z_c&height=39&width=643)


再由像素-相机坐标系转换关系，即：

![](https://cdn.nlark.com/yuque/__latex/44826c329c6aadbf65819a7443826018.svg#card=math&code=z_cP%20%3D%20KP_c&height=16&width=73)


求得相机坐标系下的坐标

![](https://cdn.nlark.com/yuque/__latex/069e119755460d181d1e735a4639ee34.svg#card=math&code=x_%7Bc%7D%20%3D%20%5Cfrac%20%7Bz_c%28x%20-%20%20%7Bc_x%7D%29%7D%20%7Bf_x%7D%20%5C%5C%0Ay_%7Bc%7D%20%3D%20%5Cfrac%20%7Bz_c%28y%20-%20%7Bc_y%7D%29%7D%7Bf_y%7D&height=86&width=643)

<div align="center">
​ ​​ <img src="https://cdn.nlark.com/yuque/0/2020/png/2394483/1598187337074-54f72cc9-8d91-4c1e-9f5a-b0598192fa46.png" width="50%" height="50%">
  <br> 图 5.5 机器人像素坐标 </br>
</div>


根据上述公式，现在我们已经得到了哨岗相机相机坐标系下的目标点空间位置坐标，由于默认的相机坐标系是![](https://cdn.nlark.com/yuque/__latex/fbade9e36a3f36d3d676c1b808451dd7.svg#card=math&code=z&height=10&width=7)轴垂直相机光心向前的，初次之外，该坐标系的![](https://cdn.nlark.com/yuque/__latex/9dd4e461268c8034f5c8564e155c67a6.svg#card=math&code=x&height=10&width=8)轴与![](https://cdn.nlark.com/yuque/__latex/415290769594460e2e485922904f345d.svg#card=math&code=y&height=12&width=7)轴与我们规定的相机自身的坐标系也稍有区别,如下图所示。图中相机坐标系的![](https://cdn.nlark.com/yuque/__latex/9dd4e461268c8034f5c8564e155c67a6.svg#card=math&code=x&height=10&width=8)轴是垂直光心向前的，三个坐标轴分别为![](https://cdn.nlark.com/yuque/__latex/9dd4e461268c8034f5c8564e155c67a6.svg#card=math&code=x&height=10&width=8)轴－红色，![](https://cdn.nlark.com/yuque/__latex/415290769594460e2e485922904f345d.svg#card=math&code=y&height=12&width=7)轴－绿色，![](https://cdn.nlark.com/yuque/__latex/fbade9e36a3f36d3d676c1b808451dd7.svg#card=math&code=z&height=10&width=7)轴－蓝色。


<div align="center">
​ ​​ <img src="https://cdn.nlark.com/yuque/0/2020/png/2394483/1598190782801-635e474d-aa3e-4cbb-9187-d1e3a74bd161.png" width="50%" height="50%">
  <br> 图 5.6 相机坐标系 </br>
</div>

图 3.9 相机坐标系

设后者（我们所规定的）坐标系内的坐标点为![](https://cdn.nlark.com/yuque/__latex/b1c82d88b16b8d391d7533f962962565.svg#card=math&code=P_%7Bmid%7D%28x_m%2Cy_m%2Cz_m%29&height=18&width=109),转换的关系即：

![](https://cdn.nlark.com/yuque/__latex/31c62852ae1077e9978b408dd988b955.svg#card=math&code=%5Cbegin%7Bcases%7D%0Ax_m%20%3D%20z_c%20%5C%5C%0Ay_m%20%3D%20-x_c%20%5C%5C%0Az_m%20%3D%20-y_c%0A%5Cend%7Bcases%7D&height=54&width=82)


之后，我们由相机位姿求解模块获得的结果，即从世界坐标系（如下图所示）到我们规定的相机坐标系的转换关系，可以求得之前归一化平面上的点在世界坐标系的坐标，我们连接该点到相机的光心，得到一条射线，现在求该射线与世界坐标系下机器人所在平面，近似为![](https://cdn.nlark.com/yuque/__latex/8fcd01a17ad602c542f98b916cba57f4.svg#card=math&code=z%3D0&height=13&width=34)的交点，即可获得机器人在世界坐标系下的坐标点。

我们设相机位姿求解的结果为![](https://cdn.nlark.com/yuque/__latex/c691025011897dc5e2d37ec60b350def.svg#card=math&code=R_%7Bwc%7D%2CT_%7Bwc%7D%0A&height=16&width=53),世界坐标系下的点设为![](https://cdn.nlark.com/yuque/__latex/1e83b802cad5c18925bb2a7511ab903b.svg#card=math&code=P_w%28x_w%2Cy_w%2Cz_w%29&height=18&width=93)，他们分别表示从相机坐标系到世界坐标系坐标转换的旋转矩阵和平移矩阵，则有相机－世界坐标转换关系，注意，这里的相机坐标系下的坐标点实际上是转换到我们规定的相机坐标系下的点![](https://cdn.nlark.com/yuque/__latex/526cb20877a1c9648c4c266056dfb8aa.svg#card=math&code=P_%7Bmid&height=16&width=29)。

![](https://cdn.nlark.com/yuque/__latex/61a360069c2d73d11853e566bb5c4689.svg#card=math&code=P_w%20%3D%20R_%7Bwc%7D%2AP_%7Bmid%7D%20%2B%20T_%7Bwc%7D&height=16&width=148)

最终我们得到机器人在世界坐标系下的坐标点![](https://cdn.nlark.com/yuque/__latex/7ba201de8f4f843f3f757100ba959f11.svg#card=math&code=P_w%28x_w%2Cy_w%2C0%29&height=18&width=85),![](https://cdn.nlark.com/yuque/__latex/fbade9e36a3f36d3d676c1b808451dd7.svg#card=math&code=z&height=10&width=7)轴的坐标取决于机器人所在平面的高度，这里是取![](https://cdn.nlark.com/yuque/__latex/8fcd01a17ad602c542f98b916cba57f4.svg#card=math&code=z%3D0&height=13&width=34)的情况。在实际的测试中，最终获得的目标点与实际点的坐标误差在10-20cm左右。以下动态图展示了哨岗相机的目标定位在仿真环境中的测试效果。
（闪烁效果因为我们检测主要在实物训练集上进行，对于仿真环境，容易出现漏检测情况）

<div align="center">
​ ​​ <img src="https://cdn.nlark.com/yuque/0/2020/gif/2394508/1598498396035-02912ebd-8d48-4d7d-b2bc-30c2c583f053.gif" width="50%" height="50%">
  <br> 图 5.7 哨岗相机对四辆车进行在地图中的定位 </br>
</div>
由于在仿真环境中，红蓝机器人在哨岗相机视角中很难分辨，因此我们在仿真环境中没有识别红蓝机器人，并且通过机器人自身的定位，结合哨岗提供的所有机器人位置，完全可以分辨敌我机器人。